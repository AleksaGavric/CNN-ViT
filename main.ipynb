{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1bvsKKIBfUz",
        "outputId": "925c52f3-7e63-4b18-89a7-314555d90544"
      },
      "outputs": [],
      "source": [
        "import os, zipfile\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = os.environ['KAGGLE_USERNAME']\n",
        "os.environ['KAGGLE_KEY'] = os.environ['KAGGLE_KEY']\n",
        "\n",
        "!kaggle datasets download -d paramaggarwal/fashion-product-images-small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpb23uN16sug"
      },
      "outputs": [],
      "source": [
        "zip_path = 'fashion-product-images-small.zip'\n",
        "extract_to = '/content/'\n",
        "\n",
        "if not os.path.exists(extract_to):\n",
        "    os.makedirs(extract_to)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Impi686XwfQy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from transformers import ViTModel, ViTConfig\n",
        "from pathlib import Path\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import random\n",
        "import os\n",
        "import zipfile\n",
        "from torchvision.models import ResNet50_Weights\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tabulate import tabulate\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf5ZCTrKf_6x"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKrTviTgwuDw"
      },
      "outputs": [],
      "source": [
        "class FashionDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None, label_binarizer=None):\n",
        "        self.data_frame = df\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.transform = transform\n",
        "        self.included_cols = ['gender', 'masterCategory', 'subCategory', 'articleType']\n",
        "        self.label_binarizer = label_binarizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data_frame.iloc[idx]\n",
        "        img_name = self.img_dir / f\"{row['id']}.jpg\"\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_name).convert('RGB')\n",
        "        except (IOError, FileNotFoundError):\n",
        "            print(f\"Error opening image: {img_name}\")\n",
        "            return None, None\n",
        "\n",
        "        labels = row[self.included_cols].values.tolist()\n",
        "        encoded_labels = self.label_binarizer.transform([labels])[0]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=np.array(image))['image']\n",
        "\n",
        "        return image, torch.FloatTensor(encoded_labels)\n",
        "\n",
        "    def print_picture(self, idx):\n",
        "        row = self.data_frame.iloc[idx]\n",
        "        img_name = self.img_dir / f\"{row['id']}.jpg\"\n",
        "\n",
        "        try:\n",
        "            original_image = Image.open(img_name).convert('RGB')\n",
        "        except (IOError, FileNotFoundError):\n",
        "            print(f\"Error opening original image: {img_name}\")\n",
        "            return None, None\n",
        "\n",
        "        labels = [self.data_frame.iloc[idx][col] for col in self.included_cols]\n",
        "\n",
        "        transformed_image = None\n",
        "        if self.transform:\n",
        "            transformed_image = self.transform(image=np.array(original_image))['image']\n",
        "\n",
        "        # Display original image\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(original_image)\n",
        "        plt.title(\"Original Image\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Display transformed image\n",
        "        if transformed_image is not None:\n",
        "            transformed_image = np.transpose(transformed_image, (1, 2, 0)) \n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(transformed_image)\n",
        "            plt.title(\"Transformed Image\")\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "z4aS9oeLMctf",
        "outputId": "a6eb2d4c-938b-4808-f258-3a2a8044b6a7"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/styles.csv', on_bad_lines='skip')\n",
        "\n",
        "filters = {\n",
        "    'gender': ['Men', 'Women', 'Unisex'],\n",
        "    'masterCategory': ['Apparel', 'Accessories', 'Footwear'],\n",
        "    'subCategory': df['subCategory'].value_counts()[df['subCategory'].value_counts() > 450].index,\n",
        "    'articleType': df['articleType'].value_counts()[df['articleType'].value_counts() > 500].index\n",
        "}\n",
        "\n",
        "criteria = df[list(filters)].isin(filters).all(axis=1)\n",
        "df = df[criteria]\n",
        "df = df[df['id'].apply(lambda x: (Path('data/images') / f\"{x}.jpg\").exists())]\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=SEED)\n",
        "included_cols = ['gender', 'masterCategory', 'subCategory', 'articleType']\n",
        "all_labels = pd.concat([train_df[included_cols], val_df[included_cols]])\n",
        "\n",
        "label_binarizer = MultiLabelBinarizer()\n",
        "label_binarizer.fit(train_df[included_cols].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cSeBOm3JQsS9",
        "outputId": "44fe8e21-fc06-4eb7-d684-f885ae9f3c43"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "num_epochs = 1\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "train_dataset = FashionDataset(train_df, img_dir='data/images', transform=None, label_binarizer=label_binarizer)\n",
        "val_dataset = FashionDataset(val_df, img_dir='data/images', transform=None, label_binarizer=label_binarizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "noise_transform = A.Compose([\n",
        "    A.GaussNoise(var_limit=(10.0, 50.0)),\n",
        "    A.JpegCompression(quality_lower=50, quality_upper=100, p=0.5),\n",
        "    A.Blur(blur_limit=(3, 7), p=0.3),\n",
        "    A.Rotate(limit=30, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "noisy_dataset = FashionDataset(val_df, img_dir='data/images', transform=noise_transform, label_binarizer=label_binarizer)\n",
        "noisy_loader = DataLoader(noisy_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "noisy_dataset.print_picture(0)\n",
        "noisy_dataset.print_picture(1)\n",
        "noisy_dataset.print_picture(2)\n",
        "noisy_dataset.print_picture(3)\n",
        "noisy_dataset.print_picture(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jOI1EXKv7S4u",
        "outputId": "c7efc8f0-3212-470c-a288-8df605df1dba"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of images: {len(df)}\")\n",
        "\n",
        "columns = train_dataset.included_cols\n",
        "\n",
        "print(train_dataset.print_picture(253))\n",
        "print()\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "df['masterCategory'].value_counts().plot(kind='bar', ax=axs[0, 0], title='Number of images per masterCategory', ylabel='Number of images', xlabel='masterCategory')\n",
        "df['gender'].value_counts().plot(kind='bar', ax=axs[0, 1], title='Number of images per gender', ylabel='Number of images', xlabel='gender')\n",
        "df['subCategory'].value_counts().nlargest(10).plot(kind='bar', ax=axs[1, 0], title='Number of images per subCategory (top 10)', ylabel='Number of images', xlabel='subCategory')\n",
        "df['articleType'].value_counts().nlargest(10).plot(kind='bar', ax=axs[1, 1], title='Number of images per articleType (top 10)', ylabel='Number of images', xlabel='articleType')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "summary_stats = df[columns].describe(include='all')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "ax.xaxis.set_visible(False)\n",
        "ax.yaxis.set_visible(False)\n",
        "ax.set_frame_on(False)\n",
        "\n",
        "table = pd.plotting.table(ax, summary_stats, loc='center', cellLoc='center', colWidths=[0.2] * len(summary_stats.columns))\n",
        "\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(10)\n",
        "table.scale(1.2, 1.2)\n",
        "\n",
        "plt.savefig('summary_statistics_table.png', bbox_inches='tight', pad_inches=0.05) \n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2AlohAeSFUH"
      },
      "outputs": [],
      "source": [
        "# Residual Network CNN model\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(ResNet,self).__init__()\n",
        "    self.resnet = models.resnet50(weights=None)\n",
        "    self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.resnet(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St6smlDvSsfo"
      },
      "outputs": [],
      "source": [
        "# Vision Transformer model\n",
        "class ViT(nn.Module):\n",
        " def __init__(self, num_classes):\n",
        "   super(ViT, self).__init__()\n",
        "   self.vit = ViTModel(ViTConfig())\n",
        "   self.classifier = nn.Linear(768, num_classes)\n",
        "\n",
        " def forward(self, x):\n",
        "   outputs = self.vit(pixel_values=x).last_hidden_state\n",
        "   x = outputs[:, 0, :]\n",
        "   x = self.classifier(x)\n",
        "\n",
        "   return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL5FHfYGTApU"
      },
      "outputs": [],
      "source": [
        "num_labels = len(label_binarizer.classes_)\n",
        "\n",
        "resnet_model = ResNet(num_classes = num_labels)\n",
        "vit_model = ViT(num_classes=num_labels)\n",
        "\n",
        "label_frequency = np.zeros(num_labels)\n",
        "for labels in all_labels.values:\n",
        "    encoded_labels = label_binarizer.transform([labels.tolist()])[0]\n",
        "    label_frequency += encoded_labels\n",
        "\n",
        "epsilon = 1e-5\n",
        "label_frequency[label_frequency == 0] = epsilon\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer_resnet = optim.Adam(resnet_model.parameters(), lr = 0.001)\n",
        "optimizer_vit = optim.Adam(vit_model.parameters(), lr=0.001)\n",
        "\n",
        "lr_scheduler_resnet = StepLR(optimizer_resnet, step_size=3, gamma=0.1)\n",
        "lr_scheduler_vit = StepLR(optimizer_vit, step_size=2, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBTQ2CRx7xev"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "      def __init__(self, patience=7, verbose=False, delta=0, path ='checkpoint.pt'):\n",
        "          self.patience = patience\n",
        "          self.verbose = verbose\n",
        "          self.delta = delta\n",
        "          self.best_score = None\n",
        "          self.early_stop = False\n",
        "          self.counter = 0\n",
        "          self.path = path\n",
        "\n",
        "      def __call__(self, val_metric, model):\n",
        "          score = -val_metric\n",
        "          if self.best_score is None:\n",
        "              self.best_score = score\n",
        "              self.save_checkpoint(val_metric, model)\n",
        "          elif score < self.best_score + self.delta:\n",
        "              self.counter += 1\n",
        "              if self.counter >= self.patience:\n",
        "                  self.early_stop = True\n",
        "          else:\n",
        "            if score > self.best_score + self.delta:\n",
        "              self.save_checkpoint(val_metric, model)\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "\n",
        "      def save_checkpoint(self, val_metric, model):\n",
        "          if self.verbose:\n",
        "              print(f'Validation metric decreased ({self.best_score:.6f} --> {val_metric:.6f}).  Saving model ...')\n",
        "              torch.save(model.state_dict(), self.path)\n",
        "\n",
        "early_stopping_resnet = EarlyStopping(patience=5, verbose = True, path = 'resnet_checkpoint.pt')\n",
        "early_stopping_vit = EarlyStopping(patience=5, verbose = True, path = 'vit_checkpoint.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NykNJfr6gt2"
      },
      "outputs": [],
      "source": [
        "losses_resnet = [1]\n",
        "losses_vit = [1]\n",
        "\n",
        "f1_scores_resnet = [0]\n",
        "f1_scores_vit = [0]\n",
        "\n",
        "def train_model(model, dataloader, criterion, optimizer, scheduler, epoch, device):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        predictions = torch.sigmoid(outputs)\n",
        "        predictions = (predictions > 0.3).float()\n",
        "\n",
        "        all_labels.append(labels.cpu().numpy())\n",
        "        preds = predictions.cpu().numpy()\n",
        "        all_predictions.append(preds)\n",
        "\n",
        "        # doing \\r escape just to not have huge stdout\n",
        "        print(f'\\rEpoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(dataloader)}]', end='')\n",
        "\n",
        "    all_labels = np.concatenate(all_labels, axis=0)\n",
        "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
        "\n",
        "    all_labels = all_labels.ravel()\n",
        "    all_predictions = all_predictions.ravel()\n",
        "\n",
        "    epoch_f1 = f1_score(all_labels, all_predictions, average=\"micro\")\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "    if model == resnet_model:\n",
        "        losses_resnet.append(avg_loss)\n",
        "        f1_scores_resnet.append(epoch_f1)\n",
        "    else:\n",
        "        losses_vit.append(avg_loss)\n",
        "        f1_scores_vit.append(epoch_f1)\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion, device, epoch):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            predictions = torch.sigmoid(outputs)\n",
        "            predictions = (predictions > 0.3).float()\n",
        "            preds = predictions.cpu().numpy()\n",
        "\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "            all_predictions.append(preds)\n",
        "\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "    all_predictions = np.concatenate(all_predictions)\n",
        "\n",
        "    all_labels = all_labels.ravel() # needed to flatten this np array into a single dimension\n",
        "    all_predictions = all_predictions.ravel()\n",
        "\n",
        "    f1 = f1_score(all_labels, all_predictions, average=\"micro\")\n",
        "\n",
        "    avg_val_loss = val_loss / len(dataloader)\n",
        "    print(f'Validation Loss: {avg_val_loss:.4f}, F1 Score: {f1:.4f}')\n",
        "\n",
        "    return avg_val_loss, f1\n",
        "\n",
        "def train_and_evaluate_model(model, train_loader, test_loader, criterion, optimizer, scheduler, early_stopping, num_epochs, device):\n",
        "    for epoch in range(num_epochs):\n",
        "        train_model(model, train_loader, criterion, optimizer, scheduler, epoch, device)\n",
        "        val_loss, f1_score_val = evaluate_model(model, test_loader, criterion, device, epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "hzS3-OQuSOiL",
        "outputId": "8b8e704e-c47d-4de7-dca3-d652ab95e7b9"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "print(\"Training and Evaluating ResNet\")\n",
        "train_and_evaluate_model(resnet_model, train_loader, test_loader, criterion, optimizer_resnet, lr_scheduler_resnet, early_stopping_resnet, num_epochs, device)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = round(end_time - start_time, 2)\n",
        "print(f\"Execution time: {execution_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbkfzPCj2yPG"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "print(\"Training and Evaluating ViT\")\n",
        "train_and_evaluate_model(vit_model, train_loader, test_loader, criterion, optimizer_resnet, lr_scheduler_resnet, early_stopping_resnet, num_epochs, device)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = round(end_time - start_time, 2)\n",
        "print(f\"Execution time: {execution_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "hSjU2Ldn21X3",
        "outputId": "80dc1244-817f-48b5-92f9-4137e564ae71"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.title('Training Loss')\n",
        "plt.ylim(0, 1)\n",
        "plt.xlim(0, num_epochs)\n",
        "plt.plot(losses_resnet, label='ResNet Training Loss')\n",
        "plt.plot(losses_vit, label='ViT Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(np.arange(0, num_epochs, 1))\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.title('F1 Score')\n",
        "plt.ylim(0, 1)\n",
        "plt.xlim(0, num_epochs)\n",
        "plt.plot(f1_scores_resnet, label='ResNet F1 Score')\n",
        "plt.plot(f1_scores_vit, label='ViT F1 Score')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('F1')\n",
        "plt.xticks(np.arange(0, num_epochs, 1))\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-f0iuHWm24mf"
      },
      "outputs": [],
      "source": [
        "def get_random_images(dataset, num_images=10):\n",
        "    random_indices = random.sample(range(len(dataset)), num_images)\n",
        "    random_images = [dataset[i] for i in random_indices]\n",
        "    return random_images\n",
        "\n",
        "def predict_labels(model, image, device, threshold=0.3):\n",
        "    model.eval()\n",
        "    image = image.to(device)\n",
        "    image = image.unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        predictions = torch.sigmoid(output)\n",
        "\n",
        "    return (predictions > threshold).cpu().numpy()[0]\n",
        "\n",
        "def map_labels_to_categories(labels, dataset):\n",
        "    label_map = {\n",
        "        \"masterCategory\" : None,\n",
        "        \"subCategory\" :  None,\n",
        "        \"articleType\" : None,\n",
        "        \"gender\" : None\n",
        "    }\n",
        "\n",
        "    for label in labels:\n",
        "        for col in dataset.included_cols:\n",
        "            if label in dataset.data_frame[col].values:\n",
        "                label_map[col] = label\n",
        "                break\n",
        "\n",
        "    return label_map\n",
        "\n",
        "def get_category_label_string(label_map):\n",
        "    return '\\n'.join([f\"{category}: {label}\" for category, label in label_map.items()])\n",
        "\n",
        "def plot_images_with_predictions(dataset, label_binarizer, num_images=5, device='cuda'):\n",
        "    fig, axs = plt.subplots(num_images, 4, figsize=(15, 4 * num_images))\n",
        "    fig.tight_layout()\n",
        "\n",
        "    for i, (image, ground_truth) in enumerate(get_random_images(dataset, num_images)):\n",
        "        ground_truth_np = ground_truth.cpu().numpy()\n",
        "        ground_truth_labels = label_binarizer.classes_[ground_truth_np.astype(bool)]\n",
        "\n",
        "        image = np.clip(image, 0.0, 1.0)\n",
        "        axs[i, 0].imshow(image.permute(1, 2, 0))\n",
        "        axs[i, 0].axis('off')\n",
        "\n",
        "        ground_truth_info = map_labels_to_categories(ground_truth_labels, dataset)\n",
        "\n",
        "        axs[i, 1].text(0.5, 0.6, f\"Ground Truth\", ha='center', va='center', wrap=True, fontweight=\"bold\")\n",
        "        axs[i, 1].text(0.5, 0.4, f\"{get_category_label_string(ground_truth_info)}\", ha='center', va='center', wrap=True)\n",
        "        axs[i, 1].axis('off')\n",
        "\n",
        "        resnet_predictions = predict_labels(resnet_model, image, device)\n",
        "        resnet_predictions_labels = [label_binarizer.classes_[j] for j, pred in enumerate(resnet_predictions) if pred]\n",
        "        resnet_predictions_info = map_labels_to_categories(resnet_predictions_labels, dataset)\n",
        "        resnet_matching = sum(1 for key, value in ground_truth_info.items() if key in resnet_predictions_info and resnet_predictions_info[key] == value)\n",
        "\n",
        "        axs[i, 2].text(0.5, 0.6, \"ResNet Prediction\", ha='center', va='center', wrap=True, fontweight=\"bold\")\n",
        "        axs[i, 2].text(0.5, 0.4, f\"{get_category_label_string(resnet_predictions_info)}\", ha='center', va='center', wrap=True)\n",
        "        axs[i, 2].text(0.5, 0.2, f\"Matches: {resnet_matching} / 4\", ha='center', va='center', wrap=True)\n",
        "        axs[i, 2].axis('off')\n",
        "\n",
        "        vit_predictions = predict_labels(vit_model, image, device)\n",
        "        vit_predictions_labels = [label_binarizer.classes_[j] for j, pred in enumerate(vit_predictions) if pred]\n",
        "        vit_predictions_info = map_labels_to_categories(vit_predictions_labels, dataset)\n",
        "        vit_matching = sum(1 for key, value in ground_truth_info.items() if key in vit_predictions_info and vit_predictions_info[key] == value)\n",
        "\n",
        "        axs[i, 3].text(0.5, 0.6, \"ViT Prediction\", ha='center', va='center', wrap=True, fontweight='bold', fontsize=10)\n",
        "        axs[i, 3].text(0.5, 0.4, f\"{get_category_label_string(vit_predictions_info)}\", ha='center', va='center', wrap=True)\n",
        "        axs[i, 3].text(0.5, 0.2, f\"Matches: {vit_matching} / 4\", ha='center', va='center', wrap=True)\n",
        "        axs[i, 3].axis('off')\n",
        "\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_images_with_predictions(val_dataset, label_binarizer)\n",
        "print()\n",
        "plot_images_with_predictions(noisy_dataset, label_binarizer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
